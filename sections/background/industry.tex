\subsection{Industry}

Apple developed Rosetta \cite{apple-rosetta} to aid in the transition from their earlier PowerPC based Macs to the, at the time, new Intel based macs. This software was thus a binary translator from PowerPC to x86, based off of QuickTransit by Transitive Corporation \cite{cnet-rosetta}. Rosetta was unable to emulate programs that utilised AltiVec instructions (a SIMD ISA extension). Rosetta was shown to have poor performance when emulating computationally heavy programs \cite{rosetta-perf}. Unlike Rosetta, which is proprietary and commercial, my work will be open source and free to use.

Microsoft developed an x86 to ARM emulator as part of Windows 10 for ARM \cite{docs-win10-arm-emu}, utilising the WOW64 \cite{WOW64} layer of Windows 10. Recently, this emulation layer was extended to support x64 binaries running under Windows 10 for ARM \cite{win10-arm-x64-emu}. The emulator utilises a JIT compiler to convert blocks of x86 to native ARM code, which are cached by a background service \cite{docs-win10-arm-emu, blackberry-win10-arm-emu}. This artefact caching allows subsequent runs to benefit from the compilation incurred in initial runs, helping to amortise the initial compilation cost and improving the performance of subsequent executions. Despite this, the emulation was shown to have very poor performance in comparison to native applications \cite{win10-arm-x64-emu-perf1, win10-arm-x64-emu-perf2}. My emulator will employ a JIT compiler with an in process artefact cache, however I will not be exploring the technique of persisting the JIT artefacts between runs.

Recently, Apple developed Rosetta 2 \cite{rosetta2} in house to aid in the transition from the Intel based Macs to their new ARM based Apple Silicon Macs \cite{rosetta2, apple-silicon}. Rosetta 2 reportedly employs an AOT translation technique, in which portions of the program are converted before it is first executed \cite{rosetta2-aot, ars-technica-big-sur}. This technique involves statically analysing portions of code in the binary and translating them ahead of time which are stored in an artefact cache; any new code encountered at runtime falls back to a JIT. This is a similar technique to that employed by Microsoft, but with the addition of the static AOT lookahead. Whilst this technique causes longer than desirable initial program boot times \cite{rosetta2-slow-launch}, Rosetta 2 has been shown to have much higher emulation performance than either the original Rosetta or Microsoft's ARM emulation \cite{rosetta2-perf}. The Apple M1 SOC reportedly includes hardware support for the x86 memory consistency model, which may attribute to Rosetta 2's performance success \cite{rosetta2-infoq}. Just like the original Rosetta, Rosetta 2 is unable to emulate programs utilising new SIMD ISA extensions such as AVX, AVX2, and AVX512 \cite{rosetta2}. Unlike Rosetta 2, I will not be exploring any AOT techniques as they cannot be employed in singularity and will focus on the JIT compilation that Rosetta 2 uses as a fallback. Furthermore, my work will not be tied to any custom hardware requirements and will operate purely in software.

QEMU `is a generic and open source machine emulator and virtualizer' \cite{qemu}. QEMU utilises a decoupled architecture in which the front end converts source instructions into tiny code generator (TCG) ops which are then converted into source instructions by the backend \cite{qemu-tcg}. The TCG ops are an abstraction layer frequently referred to as an intermediate representation (IR); it brings a large benefit in modularity and decoupling but sacrifices some performance by introducing additional overhead. I do not initially plan on exploring this IR technique due to this overhead. QEMU's TCG is powered by a JIT compiler, but they also employ a tiny code interpreter (TCI) to provide host agnostic emulation of TCG ops. QEMU provides a multithreaded option for the TCG, however this is to allow multithreaded emulation of a multithreaded system \cite{qemu-tcg-multithreading}. I will not be exploring this as my project emulates a single threaded system, however I will explore utilising multiple worker threads to accelerate a JIT-Interpreter hybrid, something that QEMU does not support. QEMU also offers a kernel based virtual machine (KVM) that allows it to bypass the TCG/TCI and only emulate the kernel when the host and source architecture match, allowing for increased performance. I will not be exploring this technique as my project is focused on binary translation and not system virtualization.